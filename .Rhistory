runApp('/poppy/programs/jeagan/examples/shiny app downloader example.R')
runApp('/poppy/programs/jeagan/examples/shiny app downloader example.R')
runApp('/poppy/programs/jeagan/examples/shiny app downloader example.R')
# generating policy wheels
plot_policy_wheels(data = df_wide,
# Ordering policies by name:
policies = c("Any Naloxone Access Law (NAL)", "NAL Standing Order or Protocol", "NAL Prescriptive Authority", "Any Good Samaritan Law (GSL)", "GSL Arrest"),
# name of the state variable
state_var = "state",
# Restrict to relevant policy intervals, for locations that implemented the policy
policy_intervals = c(2010, 2015, 2020),
plot_colors = c("#1f77b4", "#ff7f0e", "#FFFF00", "#dab8e5", "#9467bd"),
legend_args = list(x = "center", xjust = 0.5, y.intersp = 1.3, x.intersp = 1.3, cex = 2.5, pt.cex = 2.7, bty = "n", ncol = 2),
panel_width = 4,
panel_height = 5,
# where should the graph be saved?
out_file = "www/policy_wheel_1.svg")
# displaying the new graph
knitr::include_graphics("www/policy_wheel_1.svg")
# generating policy wheels
plot_policy_wheels(data = df_wide,
# Ordering policies by name:
policies = c("Any Naloxone Access Law (NAL)", "NAL Standing Order or Protocol", "NAL Prescriptive Authority", "Any Good Samaritan Law (GSL)", "GSL Arrest"),
# name of the state variable
state_var = "state",
# Restrict to relevant policy intervals, for locations that implemented the policy
policy_intervals = c(2010, 2013, 2016, 2019, 2021),
plot_colors = c("#1f77b4", "#ff7f0e", "#FFFF00", "#dab8e5", "#9467bd"),
legend_args = list(x = "center", xjust = 0.5, y.intersp = 1.3, x.intersp = 1.3, cex = 2.5, pt.cex = 2.7, bty = "n", ncol = 2),
panel_width = 4,
panel_height = 5,
# where should the graph be saved?
out_file = "www/policy_wheel_1.svg")
# generating policy wheels
plot_policy_wheels(data = df_wide,
# Ordering policies by name:
policies = c("Any Naloxone Access Law (NAL)", "NAL Standing Order or Protocol", "NAL Prescriptive Authority", "Any Good Samaritan Law (GSL)", "GSL Arrest"),
# name of the state variable
state_var = "state",
# Restrict to relevant policy intervals, for locations that implemented the policy
policy_intervals = c(2010, 2013, 2016, 2019, 2021),
plot_colors = c("#1f77b4", "#ff7f0e", "#FFFF00", "#dab8e5", "#9467bd"),
legend_args = list(x = "center", xjust = 0.5, y.intersp = 1.3, x.intersp = 1.3, cex = 2.5, pt.cex = 2.7, bty = "n", ncol = 2),
panel_width = 4,
panel_height = 5,
# where should the graph be saved?
out_file = "www/policy_wheel_1_revised.svg")
# displaying the new graph
knitr::include_graphics("www/policy_wheel_1_revised.svg")
# generating policy wheels
plot_policy_wheels(data = df_wide,
# Ordering policies by name:
policies = c("Any Naloxone Access Law (NAL)", "NAL Standing Order or Protocol", "NAL Prescriptive Authority", "Any Good Samaritan Law (GSL)", "GSL Arrest"),
# name of the state variable
state_var = "state",
# Restrict to relevant policy intervals, for locations that implemented the policy
policy_intervals = c(2010, 2013, 2016, 2019, 2021),
plot_colors = c("#1f77b4", "#ff7f0e", "#FFFF00", "#dab8e5", "#9467bd"),
legend_args = list(x = "center", xjust = 0.5, y.intersp = 1.3, x.intersp = 1.3, cex = 2.5, pt.cex = 2.7, bty = "n", ncol = 2),
panel_width = 4,
panel_height = 5,
nrows = 2,
ncols = 3,
# where should the graph be saved?
out_file = "www/policy_wheel_1_revised.svg")
# displaying the new graph
knitr::include_graphics("www/policy_wheel_1_revised.svg")
policies = NULL
state_var = "state"
nrows = NULL
ncols = NULL
panel_width = 7
panel_height = 6
byrow = TRUE
plot_width = 20
plot_height = 12
legend_args = list(x = "center",
xjust = 0.5, y.intersp = 1.3,
x.intersp = 1.3, cex = 3,
pt.cex = 2.7, bty = "n", ncol = 2)
out_file = NULL
policies = c("Any Naloxone Access Law (NAL)", "NAL Standing Order or Protocol", "NAL Prescriptive Authority", "Any Good Samaritan Law (GSL)", "GSL Arrest")
# name of the state variable
state_var = "state"
# Restrict to relevant policy intervals, for locations that implemented the policy
policy_intervals = c(2010, 2015, 2020)
plot_colors = c("#1f77b4", "#ff7f0e", "#FFFF00", "#dab8e5", "#9467bd")
legend_args = list(x = "center", xjust = 0.5, y.intersp = 1.3, x.intersp = 1.3, cex = 2.5, pt.cex = 2.7, bty = "n", ncol = 2)
panel_width = 4
panel_height = 5
data = df_wide
# Ordering policies by name:
policies = c("Any Naloxone Access Law (NAL)", "NAL Standing Order or Protocol", "NAL Prescriptive Authority", "Any Good Samaritan Law (GSL)", "GSL Arrest")
# name of the state variabl
state_var = "state"
# Restrict to relevant policy intervals, for locations that impleented the policy
policy_intervals = c(2010, 2013, 2016, 2019, 2021)
plot_colors = c("#1f77b4", "#ff7f0e", "#FFFF00", "#dab8e5", "#9467bd"
legend_args = list(x = "center", xjust = 0.5, y.intersp = 1.3, x.intersp = 1.3, cex = 2.5, pt.cex = 2.7, bty = "n", ncol = 2),
legend_args = list(x = "center", xjust = 0.5, y.intersp = 1.3, x.intersp = 1.3, cex = 2.5, pt.cex = 2.7, bty = "n", ncol = 2)
panel_width = 4
panel_height = 5
nrows = 2
ncols = 3
# where should the graph be saved?
out_file = "www/policy_wheel_1_revised.svg"
# some error catching
if(any(!(policies %in% names(data)))){
stop("make sure all values in `policies` are variable names in your data.")
}
# configuring default arguments to determine layout of policy wheels if they are not provided
if(is.null(nrows)){
nrows = ceiling(length(policy_intervals)/3)
}
if(is.null(ncols)){
ncols = min(length(policy_intervals), 3)
}
# Order states so that region-names make sense when applied to areas of the policy circle:
states <- c("OH", "WI", "DE", "FL", "GA", "MD", "NC", "SC", "VA", "DC", "WV", "IA",
"KS", "MN", "MO", "NE", "ND", "SD", "AL", "KY", "MS", "TN", "AR", "LA",
"OK", "TX", "AZ", "CO", "ID", "MT", "NV", "NM", "UT", "WY", "CA", "OR",
"WA", "AK", "HI", "CT", "ME", "MA", "NH", "RI", "VT", "NY", "NJ", "PA",
"IL", "IN", "MI")
# Load data and reshape long. Re-code policies as absorbing states at 5-year
# intervals
df = as.data.frame(data)[c(state_var, policies)]
df <- melt(setDT(df), id.vars = state_var, variable.name = "policy", value.name = "implemented")
names(df)[names(df) == state_var] <- "state"
# Convert implemented category into a 0/1, indicating if policy was implemented within
# a given year.
df[, implemented := parse_date_time(implemented, orders = c("mdy", "ymd", "B d, y", "y"))]
df[, year := year(implemented)]
df <- df[!is.na(year),]
df[, implemented := as.numeric(implemented)]
df[, implemented := 1]
# for policies that were passed before the first year of the policy wheel,
# make sure they are included
df$year[df$year < min(policy_intervals)] = min(policy_intervals)
# Set up square dataset, then subset policy database to rows with observations.
# Merge observations onto the square dataset.
year_range = min(policy_intervals):max(policy_intervals)
df_square <- expand.grid("state" = states,
"policy" = policies,
"year" = year_range)
df <- setDT(merge(df_square, df, by = c("state", "policy", "year"), all.x = T))
# Set implemented == T, for all years after the implementation year:
setorder(df, state, policy, year)
df[, implemented := nafill(.SD$implemented, "locf"), by = c("state", "policy")]
df[is.na(implemented), implemented := 0]
# Ordering policies:
policies <- unique(df$policy)
df <- df[(year %in% policy_intervals) & (implemented == 1),]
# Set up dictionary for policy wheel options:
wheel_opts <- data.table("policy" = policies,
"i" = 1:length(policies),
"col" = plot_colors)
# setting up output
if(!is.null(out_file)){
if(grepl("\\.svg", out_file)){
svg(filename = out_file,
width = plot_width, height = plot_height)
} else if(grepl("\\.pdf", out_file)){
pdf(filename = out_file,
width = plot_width, height = plot_height)
} else if(grepl("\\.png", out_file)){
png(filename = out_file,
width = plot_width, height = plot_height)
} else {
stop("currently, only .svg, .png, and .pdf are supported. Please choose a different file extention for `out_file`.")
}
}
# Create layout onto which the chart's title, legend, and policy wheels will be pasted onto
layout.mat <- matrix(1:(nrows*ncols), ncol = ncols, nrow = nrows, byrow = byrow) # plot matrix
layout.mat <- rbind(layout.mat, matrix((nrows*ncols)+1, nrow=1, ncol=ncols))
layout.mat
max(layout.mat)
leg_num = ceiling(length(policies)/2)*2
col_order <- matrix(leg_num:1, nrow = leg_num/2, ncol = 2, byrow = T)
leg_num
col_order
wheel_opts$policy
wheel_opts$policy[col_order]
col_order
c(rep(panel_height, nrows), (ceiling(length(policies)/2)*2)*.25)
rep(panel_width, ncols)
c(rep(panel_height, nrows), (ceiling(length(policies)/2)*2)*.25)
layout.mat
layout.mat
layout(layout.mat, respect = TRUE,
heights = c(rep(panel_height, nrows), (ceiling(length(policies)/2)*2)*.25),
widths = rep(panel_width, ncols))
# adding policy wheels to plot
lapply(policy_intervals, plot_policy_wheel_internal, states,  df, wheel_opts, policies)
ceiling(length(policies)/2)*2
wheel_opts$policy[col_order]
layout.mat
invisible(dev.off())
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
suppressPackageStartupMessages(library(circlize))
library(data.table)
library(plyr)
library(lubridate)
renv::status()
?renv::status()
renv::snapshot()
renv::status()
# loading packages
suppressPackageStartupMessages(library(circlize))
library(data.table)
library(plyr)
library(lubridate)
# loading functions
for(file in list.files("R")){
cat(paste0(file, "\n") )
source(paste("R", file, sep="/"))
}
# reading in a data frame where rows are states, columns are policies, and values are enactment dates
# Dates can come in the forms: "1/15/2015", "2015-01-15", "2015", or "January 15, 2015"
df_wide <- read.csv('Data/processed/example_data_wide.csv')
!dir.exists("./Data/raw/NAL")
# loading packages
library(tidyverse)
library(curl)
# Statistical mode
mode <- function(x) {
ux <- unique(x)
ux = ux[!is.na(ux)]
ux[which.max(tabulate(match(x, ux)))]
}
# if the policy data needs do be downloaded, do that
urls = c("https://www.rand.org/content/dam/rand/pubs/external_publications/EP60000/EP68648/RAND_EP68648-OBBT.zip",
"https://www.rand.org/content/dam/rand/pubs/external_publications/EP60000/EP69157/RAND_EP69157-IMD.zip",
"https://www.rand.org/content/dam/rand/pubs/external_publications/EP60000/EP68090/RAND_EP68090-NAL.zip",
"https://www.rand.org/content/dam/rand/pubs/external_publications/EP60000/EP68218/RAND_EP68218-GSL.zip",
"https://www.rand.org/content/dam/rand/pubs/external_publications/EP60000/EP68090/RAND_EP68090_Coprescrib-NAL.zip",
"https://www.rand.org/content/dam/rand/pubs/external_publications/EP60000/EP68218/RAND_EP68218-PDMP.zip",
"https://www.rand.org/content/dam/rand/pubs/external_publications/EP60000/EP67480/RAND_EP67480-MMPD.zip")
i = 1
url <- urls[i]
url
local_file <- paste0("./Data/raw/", sub(".*/", "", url))
local_file
curl_download(url, destfile = local_file)
local_file <- paste0("Data/raw/", sub(".*/", "", url))
curl_download(url, destfile = local_file)
sub(".*/", "", url)
url <- urls[i]
local_file <- paste0("Data/raw/", sub(".*/", "", url))
curl_download(url, destfile = local_file)
url
local_file
?download.file
download.file(url, destfile = local_file)
list.files("Data/raw")
list.files("Data")
if(!dir.exists("Data/raw")){
dir.create("Data/raw")
}
list.files("Data")
url <- urls[i]
local_file <- paste0("Data/raw/", sub(".*/", "", url))
download.file(url, destfile = local_file)
library(httr)
httr::GET(url, write_disk(local_file, overwrite = TRUE))
zip_con <- unz(local_file)
?unz
extract_dir <- "./Data/raw/"
zip_con <- unzip(local_file, exdir = extract_dir)
local_file
extract_dir
local_file
zip_con <- unzip(local_file, exdir = ".")
local_file
look = httr::GET(url, write_disk(local_file, overwrite = TRUE))
look$url
look$content
content(look)
###############################################################
#
# Cleaning policy data
# Joshua Eagan
# 2023-10-31
# P.I. Beth Ann Griffin
#
###############################################################
# loading packages
library(tidyverse)
library(curl)
# Statistical mode
mode <- function(x) {
ux <- unique(x)
ux = ux[!is.na(ux)]
ux[which.max(tabulate(match(x, ux)))]
}
# cleaning the policy data
policy_datasets = list()
raw_paths = c("./Data/raw/OBBT/WEB_OBBT.xlsx",
"./Data/raw/IMD/WEB_IMD-Waiver.xlsx",
"./Data/raw/NAL/WEB_NAL_1990-2022.xlsx",
"./Data/raw/GSL/WEB_GSL_1990-2021.xlsx",
"./Data/raw/Co-prescribing NAL/WEB_Coprescribing_NAL.xlsx",
"./Data/raw/PDMP 12-2020/WEB_OPTIC_PDMP.xlsx",
"./Data/raw/Medical Marijuana Policy Data/WEB_MJ Policy.xlsx")
data_names = c("obbt", "imd", "nal", "gsl", "copnal", "pdmp", "mm")
for(i in 1:length(raw_paths)){
# reading in policy data
policy_datasets[[data_names[i]]] = readxl::read_excel(raw_paths[i], sheet = 2,) %>%
dplyr::select(-starts_with("...")) %>%
rename_with(.fn = ~ paste(data_names[i], .x, sep="_"),
.cols = -c(state, year))
}
# looking at the data
purrr::map(policy_datasets, ~names(.x))
purrr::map(policy_datasets, ~dim(.x))
# checking year ranges
purrr::map(policy_datasets, ~ .x %>% pull(year) %>% unique())
# Co-prescribing only available through 2020, GSL through 2021, and NAL through 2022
# do all policy data sets track the same states?
purrr::map(policy_datasets, ~ .x %>%
pull(state) %>% unique())
# merging data sets
clean_long = policy_datasets %>% purrr::reduce(dplyr::full_join)
# creating an additional variable needed for the last policy wheel
clean_long$copnal_date_all_prescribe = clean_long$copnal_date_eff_all
clean_long$copnal_date_all_prescribe[clean_long$copnal_nat_mandate != "Mandate prescribing"] = NA
# creating a wide dataset
date_vars = names(clean_long)[grepl("_date", names(clean_long))]
# checking if there are multiple dates within one state/policy
for(i in 1:length(date_vars)){
# making a state level count of the distinct number of dates
tbl = clean_long %>% select(state, !!sym(date_vars[i])) %>%
distinct() %>%
filter(!is.na(!!sym(date_vars[i]))) %>%
pull(state) %>%
table()
# printing out the variables and states that have multiple dates
if(max(tbl) > 1){
print(paste("multiple policies passed for one state: ", date_vars[i], ": ", names(tbl[tbl>1])))
}
}
# for all policies, there is only one non-missing date associated for each state.
# therefore, information will not be lost by transitioning to wide data.
clean_wide = clean_long %>% group_by(state) %>%
summarize(across(date_vars, mode))
# ordering by state and year
clean_long = clean_long %>% arrange(state, year)
clean_long
View(clean_long)
write.csv(clean_long, file = "./Data/processed/example_data_long.csv")
write.csv(clean_wide, file = "./Data/processed/example_data_wide.csv")
deps <- renv::dependencies()
deps
?rename_with
# loading packages
library(dplyr)
library(curl)
library(readxl)
library(purrr)
# Statistical mode
mode <- function(x) {
ux <- unique(x)
ux = ux[!is.na(ux)]
ux[which.max(tabulate(match(x, ux)))]
}
# cleaning the policy data
policy_datasets = list()
raw_paths = c("./Data/raw/OBBT/WEB_OBBT.xlsx",
"./Data/raw/IMD/WEB_IMD-Waiver.xlsx",
"./Data/raw/NAL/WEB_NAL_1990-2022.xlsx",
"./Data/raw/GSL/WEB_GSL_1990-2021.xlsx",
"./Data/raw/Co-prescribing NAL/WEB_Coprescribing_NAL.xlsx",
"./Data/raw/PDMP 12-2020/WEB_OPTIC_PDMP.xlsx",
"./Data/raw/Medical Marijuana Policy Data/WEB_MJ Policy.xlsx")
data_names = c("obbt", "imd", "nal", "gsl", "copnal", "pdmp", "mm")
for(i in 1:length(raw_paths)){
# reading in policy data
policy_datasets[[data_names[i]]] = readxl::read_excel(raw_paths[i], sheet = 2,) %>%
dplyr::select(-starts_with("...")) %>%
rename_with(.fn = ~ paste(data_names[i], .x, sep="_"),
.cols = -c(state, year))
}
# looking at the data
purrr::map(policy_datasets, ~names(.x))
purrr::map(policy_datasets, ~dim(.x))
# checking year ranges
purrr::map(policy_datasets, ~ .x %>% pull(year) %>% unique())
# Co-prescribing only available through 2020, GSL through 2021, and NAL through 2022
# do all policy data sets track the same states?
purrr::map(policy_datasets, ~ .x %>%
pull(state) %>% unique())
# merging data sets
clean_long = policy_datasets %>% purrr::reduce(dplyr::full_join)
# creating an additional variable needed for the last policy wheel
clean_long$copnal_date_all_prescribe = clean_long$copnal_date_eff_all
clean_long$copnal_date_all_prescribe[clean_long$copnal_nat_mandate != "Mandate prescribing"] = NA
# creating a wide dataset
date_vars = names(clean_long)[grepl("_date", names(clean_long))]
# checking if there are multiple dates within one state/policy
for(i in 1:length(date_vars)){
# making a state level count of the distinct number of dates
tbl = clean_long %>% select(state, !!sym(date_vars[i])) %>%
distinct() %>%
filter(!is.na(!!sym(date_vars[i]))) %>%
pull(state) %>%
table()
# printing out the variables and states that have multiple dates
if(max(tbl) > 1){
print(paste("multiple policies passed for one state: ", date_vars[i], ": ", names(tbl[tbl>1])))
}
}
# for all policies, there is only one non-missing date associated for each state.
# therefore, information will not be lost by transitioning to wide data.
clean_wide = clean_long %>% group_by(state) %>%
summarize(across(date_vars, mode))
# ordering by state and year
clean_long = clean_long %>% arrange(state, year)
deps <- renv::dependencies()
deps
used_packages <- unique(deps$Package)
used
used_packages
all_packages <- renv::library()
lockfile <- renv:::lockfile.read()
library(renv)
lockfile <- renv:::lockfile.read()
all_packages <- renv::library()
?renv::clean()
renv::clean(actions="unused.packages")
###############################################################
#
# Cleaning policy data
# Joshua Eagan
# 2023-10-31
# P.I. Beth Ann Griffin
#
###############################################################
# loading packages
library(dplyr)
library(curl)
library(readxl)
library(purrr)
# Statistical mode
mode <- function(x) {
ux <- unique(x)
ux = ux[!is.na(ux)]
ux[which.max(tabulate(match(x, ux)))]
}
# cleaning the policy data
policy_datasets = list()
raw_paths = c("./Data/raw/OBBT/WEB_OBBT.xlsx",
"./Data/raw/IMD/WEB_IMD-Waiver.xlsx",
"./Data/raw/NAL/WEB_NAL_1990-2022.xlsx",
"./Data/raw/GSL/WEB_GSL_1990-2021.xlsx",
"./Data/raw/Co-prescribing NAL/WEB_Coprescribing_NAL.xlsx",
"./Data/raw/PDMP 12-2020/WEB_OPTIC_PDMP.xlsx",
"./Data/raw/Medical Marijuana Policy Data/WEB_MJ Policy.xlsx")
data_names = c("obbt", "imd", "nal", "gsl", "copnal", "pdmp", "mm")
for(i in 1:length(raw_paths)){
# reading in policy data
policy_datasets[[data_names[i]]] = readxl::read_excel(raw_paths[i], sheet = 2,) %>%
dplyr::select(-starts_with("...")) %>%
rename_with(.fn = ~ paste(data_names[i], .x, sep="_"),
.cols = -c(state, year))
}
# looking at the data
purrr::map(policy_datasets, ~names(.x))
purrr::map(policy_datasets, ~dim(.x))
# checking year ranges
purrr::map(policy_datasets, ~ .x %>% pull(year) %>% unique())
# Co-prescribing only available through 2020, GSL through 2021, and NAL through 2022
# do all policy data sets track the same states?
purrr::map(policy_datasets, ~ .x %>%
pull(state) %>% unique())
# merging data sets
clean_long = policy_datasets %>% purrr::reduce(dplyr::full_join)
# creating an additional variable needed for the last policy wheel
clean_long$copnal_date_all_prescribe = clean_long$copnal_date_eff_all
clean_long$copnal_date_all_prescribe[clean_long$copnal_nat_mandate != "Mandate prescribing"] = NA
# creating a wide dataset
date_vars = names(clean_long)[grepl("_date", names(clean_long))]
# checking if there are multiple dates within one state/policy
for(i in 1:length(date_vars)){
# making a state level count of the distinct number of dates
tbl = clean_long %>% select(state, !!sym(date_vars[i])) %>%
distinct() %>%
filter(!is.na(!!sym(date_vars[i]))) %>%
pull(state) %>%
table()
# printing out the variables and states that have multiple dates
if(max(tbl) > 1){
print(paste("multiple policies passed for one state: ", date_vars[i], ": ", names(tbl[tbl>1])))
}
}
# for all policies, there is only one non-missing date associated for each state.
# therefore, information will not be lost by transitioning to wide data.
clean_wide = clean_long %>% group_by(state) %>%
summarize(across(date_vars, mode))
# ordering by state and year
clean_long = clean_long %>% arrange(state, year)
renv::snapshot()
?svg
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
# loading packages
suppressPackageStartupMessages(library(circlize))
library(data.table)
library(plyr)
library(lubridate)
# loading functions
for(file in list.files("R")){
cat(paste0(file, "\n") )
source(paste("R", file, sep="/"))
}
